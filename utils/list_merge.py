import requests, base64, os, json, urllib.parse, re, socket

def get_content(url, timeout_sec=60):
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
        r = requests.get(url, headers=headers, timeout=timeout_sec)
        return r.text if r.status_code == 200 else ""
    except: return ""

def verify_node(host, port):
    """
    ç¬¬ä¸€æ­¥ï¼šæœ€ç¨³å¦¥çš„æ¢¯å­å­˜æ´»éªŒè¯ (TCP æ¡æ‰‹)
    ç¬¬äºŒæ­¥ï¼šè·å–çœŸå®çš„å…¬ç½‘ IP ç”¨äºå»é‡
    """
    try:
        # è·å–ç‰©ç† IP (è§£å†³åŸŸåé©¬ç”²é—®é¢˜)
        actual_ip = socket.gethostbyname(host)
        # å°è¯•å»ºç«‹ TCP è¿æ¥ (éªŒè¯æ¢¯å­æ˜¯å¦æœ‰å“åº”)
        with socket.create_connection((actual_ip, int(port)), timeout=2):
            return actual_ip, True
    except:
        return None, False

def extract_node_info(node_str):
    """ç²¾ç¡®è§£æä¸åŒåè®®çš„ Host å’Œ Port"""
    try:
        if node_str.startswith("ss://"):
            content = node_str.split("//")[1].split("#")[0]
            if "@" in content: host_port = content.split("@")[1]
            else:
                padding = '=' * (4 - len(content) % 4)
                decoded = base64.b64decode(content + padding).decode('utf-8', errors='ignore')
                host_port = decoded.split("@")[1] if "@" in decoded else decoded
        elif "://" in node_str:
            parts = node_str.split("@")
            if len(parts) > 1: host_port = parts[1].split("?")[0]
            else: return None, None
        
        if ":" in host_port:
            h = host_port.split(":")[0]
            p = host_port.split(":")[1].split("/")[0]
            return h, p
    except: pass
    return None, None

def start():
    repo = os.getenv('GITHUB_REPOSITORY', 'awwy1222/V2RayAggregator')
    raw_url = f"https://raw.githubusercontent.com/{repo}/master/sub/sub_merge.txt"
    
    with open('./sub/sub_list.json', 'r', encoding='utf-8') as f:
        sub_list = [item for item in json.load(f) if item.get('enabled')]

    all_nodes = []
    seen_features = set() # å­˜å‚¨ (IP, Port) å…ƒç»„

    print("ğŸš€ å¼€å§‹å¤šç»´åº¦éªŒè¯ä¸å»é‡...")
    for item in sub_list:
        content = get_content(item['url'], 20)
        if not content: continue
        try:
            padding = '=' * (4 - len(content.strip()) % 4)
            nodes = base64.b64decode(content.strip() + padding).decode('utf-8', errors='ignore').split('\n')
        except: nodes = content.split('\n')
        
        for n in nodes:
            n = n.strip()
            if not any(n.startswith(p) for p in ["vmess://", "ss://", "ssr://", "trojan://", "vless://"]): continue
            
            host, port = extract_node_info(n)
            if host and port:
                # éªŒè¯å­˜æ´»å¹¶è·å–ç‰©ç† IP
                actual_ip, is_alive = verify_node(host, port)
                if is_alive:
                    feature = (actual_ip, port)
                    # [ç²¾ç¡®å»é‡]ï¼šåªæœ‰ IP å’Œ ç«¯å£ éƒ½ä¸é‡å¤æ‰é€šè¿‡
                    if feature not in seen_features:
                        all_nodes.append(n)
                        seen_features.add(feature)

    print(f"âœ… ç­›é€‰å®Œæˆï¼šå·²ä»å†—ä½™èŠ‚ç‚¹ä¸­æå–å‡º {len(all_nodes)} ä¸ªçœŸå®çš„ç‰©ç†ç‹¬ç«‹èŠ‚ç‚¹")
    
    os.makedirs('./sub', exist_ok=True)
    with open('./sub/sub_merge.txt', 'w', encoding='utf-8') as f:
        f.write("\n".join(all_nodes))

    # [æœ€å‡†ç¡®çš„åˆ†ç»„æ£€æµ‹é€»è¾‘]
    local_config = f"""
mixed-port: 7890
allow-lan: true
mode: rule
log-level: info
ipv6: false

proxy-providers:
  my_nodes:
    type: http
    url: "{raw_url}"
    interval: 3600
    path: ./nodes_list.txt
    health-check:
      enable: true
      interval: 600
      url: http://www.gstatic.com/generate_204

proxy-groups:
  # --- Gemini ä¸“ç”¨ç»„ ---
  # æ ¸å¿ƒåŸç†ï¼šè®¿é—® Gemini API æ¥å£ã€‚
  # 1. å¦‚æœ IP è¢«ç¦ï¼Œè¿”å› 403 -> Clash åˆ¤å®šå¤±è´¥
  # 2. å¦‚æœåœ°åŒºä¸æ”¯æŒï¼Œè¿”å› 400 -> Clash åˆ¤å®šå¤±è´¥
  # 3. åªæœ‰çœŸæ­£èƒ½ç”¨çš„ IP æ‰ä¼šæ˜¾ç¤ºå»¶è¿Ÿï¼Œè¿›å…¥è¯¥ç»„
  - name: ğŸ¤– Gemini ä¸“ç”¨
    type: url-test
    use: [my_nodes]
    url: 'https://generativelanguage.googleapis.com/v1beta/models?key=detect'
    interval: 300
    tolerance: 50
  
  - name: ğŸš€ å…¨çƒè‡ªåŠ¨
    type: url-test
    use: [my_nodes]
    url: 'http://www.gstatic.com/generate_204'
    interval: 300

  - name: ğŸ¯ æ‰‹åŠ¨åˆ‡æ¢
    type: select
    use: [my_nodes]

rules:
  - DOMAIN-SUFFIX,gemini.google.com,ğŸ¤– Gemini ä¸“ç”¨
  - DOMAIN-SUFFIX,generativelanguage.googleapis.com,ğŸ¤– Gemini ä¸“ç”¨
  - DOMAIN-SUFFIX,aistudio.google.com,ğŸ¤– Gemini ä¸“ç”¨
  - GEOIP,CN,DIRECT
  - MATCH,ğŸš€ å…¨çƒè‡ªåŠ¨
"""
    with open('./sub/config.yaml', 'w', encoding='utf-8') as f:
        f.write(local_config)
    print("ğŸ“¦ æœ¬åœ°é…ç½® config.yaml å·²æ›´æ–°ï¼Œå»é‡ä¸ Gemini ç­–ç•¥å·²å°±ç»ªã€‚")

if __name__ == '__main__':
    start()
